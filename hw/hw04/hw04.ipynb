{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw04.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Text Analysis of Bloomberg Articles\n",
    "\n",
    "## Data Cleaning and EDA\n",
    "\n",
    "### Due Monday, July 1, 11:59 PM PT\n",
    "\n",
    "You must submit this assignment to Gradescope by the on-time deadline, Monday, July 1, 11:59 PM PT. Please read the syllabus for the grace period policy. No late submissions beyond the grace period will be accepted. **We strongly encourage you to submit your work to Gradescope several hours before the stated deadline.** This way, you will have ample time to reach out to staff for support if you encounter difficulties with submission. While course staff is happy to help guide you with submitting your assignment ahead of the deadline, we will not respond to last-minute requests for assistance.\n",
    "\n",
    "Please read the instructions carefully when submitting your work to Gradescope.\n",
    "\n",
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the homework, we ask that you **write your solutions individually**. If you do discuss the assignments with others, please **include their names** below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators**: _list collaborators here_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Assignment\n",
    "\n",
    "Welcome to Homework 4! For this assignment, we will work with Bloomberg news articles on Microsoft and Microsoft stock data (MSFT).\n",
    "\n",
    "In this assignment, you will gain practice with:\n",
    "\n",
    "- Conducting data cleaning and EDA on a text-based dataset,\n",
    "- Manipulating data in `pandas` with the `datetime` and `string` accessors,\n",
    "- Writing regular expressions and using `pandas` regex methods, and\n",
    "- Performing sentiment analysis on text using DistilBERT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook. \n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "import re\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ds100_utils import *\n",
    "\n",
    "# Ensure that pandas shows at least 280 characters in columns, so we can see full articles.\n",
    "pd.set_option(\"max_colwidth\", 280)\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Breakdown\n",
    "\n",
    "Question | Manual| Points\n",
    "--- |---| ---\n",
    "1a |No| 1\n",
    "1b |No| 1\n",
    "1c |No| 3\n",
    "1d |Yes| 1\n",
    "2a |No| 2\n",
    "2b |No| 1\n",
    "2c |No| 2\n",
    "2di |No| 1\n",
    "2dii |Yes| 1\n",
    "3ai |No| 0.5\n",
    "3aii |No| 0.5\n",
    "3aii |No| 1\n",
    "3b |No| 2\n",
    "3ci |No| 1\n",
    "3cii |Yes| 1\n",
    "**Total** | **3** | **19**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Start\n",
    "\n",
    "For each question in the assignment, please write down your answer in the answer cell(s) right below the question.\n",
    "\n",
    "We understand that it is helpful to have extra cells breaking down the process towards reaching your final answer. If you happen to create new cells below your answer to run code, **NEVER** add cells between a question cell and the answer cell below it. It will cause errors when we run the autograder, and it will sometimes cause a failure to generate the PDF file.\n",
    "\n",
    "**Important note: The local autograder tests will not be comprehensive. You can pass the automated tests in your notebook but still fail tests on Gradescope after the grades are released.** Please be sure to check your results carefully.\n",
    "\n",
    "Finally, unless we state otherwise, **do not use for loops or list comprehensions**. The majority of this assignment can be done using built-in commands in `pandas` and `NumPy`.\n",
    "\n",
    "### Debugging Guide\n",
    "\n",
    "If you run into any technical issues, we highly recommend checking out the [Data 100 Debugging Guide](https://ds100.org/debugging-guide/). In this guide, you can find general questions about Datahub, Gradescope, and common `pandas` and RegEx errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 1: Importing the Data\n",
    "\n",
    "The data for this assignment is a subset of the financial news dataset from [this github repo](https://github.com/philipperemy/financial-news-dataset). The original datasets are no longer available online due to copyright issues, but we were allowed access for educational purposes. The data in the file `data/msft_bloomberg_news.txt` has been filtered to just Bloomberg articles published between 2010 to 2013 (inclusive) with text that contains \"Microsoft\" or \"MSFT\" (Microsoft's stock name).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1a\n",
    "\n",
    "Let's examine the contents of the `data/msft_bloomberg_news.txt` file. Using the [`open` function](https://docs.python.org/3/library/functions.html#open) and [`read` operation](https://docs.python.org/3/tutorial/inputoutput.html#methods-of-file-objects) on a `python` file object, read **the first 1000 characters** in `data/msft_bloomberg_news.txt` and store your result in the variable `q1a`. Then, display the result so you can read it.\n",
    "\n",
    "**CAUTION: Viewing the contents of large files in a Jupyter Notebook could crash your browser. Be careful not to print the entire contents of the file.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "print(q1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1b\n",
    "\n",
    "Based on the printed output you got from `q1a`, what format is the data in? Answer this question by entering the letter corresponding to the right format in the variable `q1b` below.\n",
    "\n",
    "**CAUTION: As a reminder, viewing the contents of large files in a Jupyter Notebook could crash your browser. Be careful not to print the entire contents of the file, and do not use the file explorer to open data files directly.**\n",
    "\n",
    "**A.** CSV<br/>\n",
    "**B.** HTML<br/>\n",
    "**C.** JavaScript Object Notation (JSON)<br/>\n",
    "**D.** Excel XML\n",
    "\n",
    "Answer in the following cell. Your answer should be a string, either `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1b = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1c\n",
    "\n",
    "`pandas` has built-in readers for many different file formats, including the file format used here to store news articles. To learn more about these, check out the documentation for\n",
    "\n",
    "- `pd.read_csv` [(docs)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n",
    "- `pd.read_html`[(docs)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_html.html)\n",
    "- `pd.read_json`[(docs)](https://pandas.pydata.org/docs/reference/api/pandas.read_json.html)\n",
    "- `pd.read_excel`[(docs)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html).\n",
    "\n",
    "For this question, use one of these functions to:\n",
    "1. Load the file `msft_bloomberg_news.txt` in the data folder as a `DataFrame` into the variable `msft_news_df`.\n",
    "2. Set the **index** of `msft_news_df` to correspond to the `id` of each news article.\n",
    "\n",
    "\n",
    "**Hint:** If your code is taking a while to run, you should review your answers to `q1a` and `q1b`; you may have used the incorrect data loading function for the type of the given file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "msft_news_df = ...\n",
    "msft_news_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1d\n",
    "\n",
    "Suppose we are interested in using the news to predict future stock values. What additional data would we need to predict stock prices, and how could we connect that data to news articles? In addition, what attributes or characteristics of the news might help predict the stock value? Please refer to specific examples from `msft_news_df`. Reminder that the use of AI-assisted methods, e.g. ChatGPT, to generate written or code solutions is prohibited. Please see the [course syllabus](https://ds100.org/su24/syllabus/) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 2: Time Analysis\n",
    "\n",
    "After loading in the data, we can start exploring news articles by analyzing the relationships between the release dates (date of publication) and different topics and companies.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "### Question 2a\n",
    "\n",
    "First, let's extract the date and time from the `released_at` column in `msft_news_df`. Notice that the date and time are encoded in the following format:\n",
    "\n",
    "```\n",
    "<date>May 29 2012</date> <time>09:40:58</time>\n",
    "<date>May 18 2011</date> <time>22:42:40</time>\n",
    "<date>August 15 2012</date> <time>00:09:02</time>\n",
    "<date>July 1 2011</date> <time>22:12:37</time>\n",
    "...\n",
    "```\n",
    "\n",
    "There are several ways to convert this to a `Timestamp` object that we can use more easily. However, for this assignment, we are going to use string manipulation functions. \n",
    "\n",
    "Create a regular expression that extracts the Month, Day, Year, Hour, Minute, and Second from the `msft_news_df[\"released_at\"]` column. You should create a new `DataFrame` called `dates` that contains:\n",
    "1. The same index as `msft_news_df` (`id`) and\n",
    "2. Column labels: `\"Month\"`, `\"Day\"`, `\"Year\"`, `\"Hour\"`, `\"Minute\"`, `\"Second\"`.\n",
    "\n",
    "Additionally, convert all numerical values (`\"Year\"`, `\"Day\"`, `\"Hour\"`, `\"Minute\"`, `\"Second\"`) to type `int`.\n",
    "\n",
    "**Hint 1:** You should use the [`Series.str.extract`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html) function.\n",
    "\n",
    "**Hint 2:** Don't forget to use raw strings and capture groups. Copy the above example text into [regex101.com](https://regex101.com/) to experiment with your regular expressions.\n",
    "\n",
    "**Hint 3:** It might be helpful to break this up into a couple of steps (e.g., first extract date values such as Month, Day, and Year and then extract time values such as Hour, Minute, and Second)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2b\n",
    "\n",
    "Now that we've figured out how to extract dates, create a new `DataFrame` called `msft_news_2010` that only contains articles released in 2010. This `DataFrame` should contain:\n",
    "1. An index of `id` and\n",
    "2. Columns: `\"title\"`, `\"released_at\"`, `\"content\"`, `\"path\"`, `\"Month\"`, `\"Day\"`, and `\"Year\"`.\n",
    "\n",
    "**Hint:** Consider [merging](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) `msft_news_df` with `dates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "msft_news_2010.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2c\n",
    "\n",
    "After processing the article release dates, we can analyze articles about different topics and companies. Note that all the articles in the provided dataset mention Microsoft/MSFT, but they can also mention other companies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "For each company in the list of `companies` (provided below), add a boolean column to the `msft_news_df` `DataFrame` indicating whether the corresponding company is mentioned in the text of the article. Ultimately, you should add six new columns (`\"amazon\"`, `\"nintendo\"`, `\"apple\"`, `\"sony\"`, `\"facebook\"`, `\"netflix\"` ) containing `True`/`False` values to the `DataFrame`. You may use a for loop over the list of companies.\n",
    "\n",
    "The table should look similar to the row pictured below:\n",
    "\n",
    "<img src = \"images/q2c.png\" width = \"1000\">\n",
    "\n",
    "**Note:** Make the contents of the articles lowercase before searching for the keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "companies = [\"amazon\", \"nintendo\", \"apple\", \"sony\", \"facebook\", \"netflix\"]\n",
    "\n",
    "...\n",
    "\n",
    "msft_news_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2d\n",
    "\n",
    "Now, we can put everything together to analyze the release dates and volume of articles for different companies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 2d, Part i\n",
    "\n",
    "Create a new `DataFrame` called `year_news` that contains the number of articles mentioning each company in the list `companies` after 2010 (inclusive). `year_news` should have six columns (one column for each company), and the index of this `DataFrame` should be the release year `\"Year\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year_news = ...\n",
    "year_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2di\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 2d, Part ii\n",
    "\n",
    "Given your code in the previous part is correct, after running the cell below, you should be able to see the number of articles released mentioning `companies` for each year. The plot should look like this:\n",
    "<center>\n",
    "<img src = \"images/num_articles.png\" width = \"500\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for company in companies:\n",
    "    sns.lineplot(data=year_news.reset_index(),\n",
    "                 x=\"Year\",\n",
    "                 y=company,\n",
    "                 label=company)\n",
    "plt.legend(fontsize=\"12\")\n",
    "plt.xticks(np.arange(2010, 2014), np.arange(2010, 2014))\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.title(\"Number of Articles Released (2010-2013)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "What trends do you notice in the plot above? Feel free to reference or Google any events to explain the trends seen in the graph. What are some limitations of using data and the corresponding plot to analyze the performance of different companies or trends?\n",
    "\n",
    "**Hint:** Remember the source of the articles and the subset of the articles we are analyzing in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 3: Sentiment Analysis\n",
    "\n",
    "In this section, we will continue building on our past analysis and specifically look at the **sentiment of each article** —— this will lead us to a much more direct and detailed understanding of how these articles can be used in different applications. **Sentiment analysis** is generally the computational task of classifying the emotions in a body of text as positively or negatively charged.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a fine-tuned version of the **DistilBERT** model ([github](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation), [original paper](https://arxiv.org/abs/1910.01108)) to analyze the sentiment of Bloomberg news articles. DistilBERT is a neural network-based language model (a close relative to ChatGPT); we will use the model checkpoint specifically trained for sentiment analysis. These models are not in scope for Data 100, and we don't expect you to know how they work; take CS182: Neural Networks or Data 102: Data, Inference, and Decisions if you're interested in learning more. We are using them here to show how easy (and useful) these technologies have become.\n",
    "\n",
    "We can use the [HuggingFace library](https://huggingface.co/) to build the sentiment analysis pipeline and load the model. [Here](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english) is the card of the model checkpoint we will use for this assignment: the model card contains general information about the model, including the base model used, training arguments, training data, etc. Again, you don't need to know this for the course, but knowing about model cards is important when you start to use these techniques in your careers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 3a\n",
    "\n",
    "As running all the articles through the model will take a while, let's first focus on articles released in 2010. We have already filtered these articles in `q2b` and assigned them to the `DataFrame` `msft_news_2010`.\n",
    "\n",
    "Due to model input size constraints, a maximum of 512 words (tokens), and limited computational resources on Datahub, we cannot load the full articles into the pipeline. Instead, we can look at the first sentence that mentions Microsoft in each article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 3a, Part i\n",
    "\n",
    "Assign `microsoft_re` to a regular expression that **matches all sentences referencing \"microsoft\" or \"msft\" (in lowercase)**. You should assume all sentences end with `.`, `?`, or `!` and that these punctuation characters are not used for any other purpose. This is of course not true in practice (e.g., this example! and 3.14), but we will often make these simplifying assumptions to enable progress in data analysis.\n",
    "\n",
    "You should develop and test your regular expression using [regex101.com](https://regex101.com/). Here are some practice sentences.\n",
    "\n",
    "```\n",
    "have you ever worked at microsoft? i once did. microsoft is known for\n",
    "their research in ai. it is abbreviated as msft.\n",
    "```\n",
    "\n",
    "**Hint 1:** Consider using the negation character class `r\"[^.!?]\"`\n",
    "\n",
    "**Hint 2:** Some sentences will wrap across lines, but the `.` will not match across new lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "microsoft_re = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 3a, Part ii\n",
    "\n",
    "Now, using the regular expression from Part i, we want to extract the **first sentence** mentioning \"microsoft\" or \"msft\" from each article in `msft_news_2010`.\n",
    "\n",
    "Specifically, you should:\n",
    "\n",
    "1. Canonicalize the content of the articles (`content` column) by converting the text to lowercase,\n",
    "2. Use the `microsoft_re` regular expression to extract the first sentence mentioning \"microsoft\" or \"msft\" in each article **without** using `Series.apply`, and\n",
    "3. Create a new column `first_sentence` in `msft_news_2010` with these values. \n",
    "\n",
    "\n",
    "**Hint 1:** The `Series.str.findall` function might be useful (might take around a minute to run).\n",
    "\n",
    "**Hint 2:** We only want the first sentence from each article that matches `microsoft_re`. Take a look at the [documentation for `Series.str.findall`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.findall.html) to see how this function handles multiple matches to `microsoft_re`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "msft_news_2010.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3aii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 3a, Part iii\n",
    "\n",
    "To avoid straining DataHub too much, we have preloaded the sentiments of the sentences analyzed in this assignment, as generated by the model. You can use the `sentiment` dataframe below to access these sentiments. This dataframe contains a label and score for each corresponding sentence in `msft_news_2010`. That is, the first row of `sentiment` contains the score for the first sentence in the `first_sentence` column of `msft_news_2010`, the second row contains the score for the second sentence, and so on.\n",
    "\n",
    "Run the following cell to see an example of the model's output for two of these sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Load the sentiments as generated by the model\n",
    "def sentiment_analysis():\n",
    "    from ds100_utils import fetch_and_cache\n",
    "    import pickle\n",
    "    url = \"https://github.com/DS-100/sp24/raw/main/resources/assets/datasets/hw3_sentiments.pkl\"\n",
    "    path = fetch_and_cache(url, \"tmp-sentiment.pkl\")\n",
    "    with open(path, \"rb\") as f:\n",
    "        out = pickle.load(f)\n",
    "    return out\n",
    "\n",
    "sentiment = pd.DataFrame(sentiment_analysis(), index = msft_news_2010.index)\n",
    "sentiment.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As you can see, the model can determine the sentiment of phrases/sentences (not just words). In addition to a sentiment label (`'NEGATIVE'` or `'POSITIVE'`), the model also measures the phrase's **polarity**, indicating how strongly negative or positive it is on a scale of 0 to 1. For example:\n",
    "- for the first sentence in the `first_sentence` column, the model indicates a strong negative polarity with a score of 0.9986.\n",
    "- for the second sentence, the model indicates a positive polarity (but not as strong), with a score of 0.6245.\n",
    "\n",
    "Using this model, let's now get the **numerical** sentiment score of the first sentence that mentions \"microsoft\" or \"msft\" for each article. We calculate the numerical sentiment score by combining the sentiment label and the polarity. This new score should be negative when the label is `'NEGATIVE'`. For example, the first sentence has a numerical sentiment score of -0.9986, since its label is `'NEGATIVE'` and its polarity score is 0.9986 (as printed out above).\n",
    "\n",
    "Add a new column `sentence_sentiment` to `msft_news_2010` with these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "msft_news_2010.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3aiii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3b\n",
    "\n",
    "We can now turn to an alternative, more accurate way of determining the sentiment score of articles--getting the sentiment based on the entire text, rather than getting sentiment based on the first sentence including \"microsoft\" or \"msft\" in the text. Let's load in `data/article_sentiment_logs.csv`, which contains sentiment scores of the full articles as a `DataFrame` `full_sentiments`. In this file, you are provided with logs which include the `id`, `score`, and `label` (\"N\" for \"NEGATIVE\" and \"P\" for \"POSITIVE\") in the following format: \n",
    "\n",
    "```\n",
    "<device:1> <id:77243971> <result: [0.9963290095329285 (N)]>\n",
    "<device:0> <id:14799046> <result: [0.9980687499046326 (N)]>\n",
    "<device:1> <id:43064156> <result: [0.997868537902832 (N)]>\n",
    "<device:1> <id:29402508> <result: [0.9924335479736328 (N)]>\n",
    "...\n",
    "```\n",
    "\n",
    "Run the following cell to load in the `DataFrame` and see what it contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Run this cell; no further action is needed\n",
    "full_sentiments = pd.read_csv('data/article_sentiment_logs.csv')\n",
    "full_sentiments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Using the logs you should:\n",
    "1. Modify `full_sentiments` so it ultimately just contains the `id` and `content_sentiment` (a number ranging from -1 to 1).\n",
    "2. Then, merge this with `msft_news_2010` so we can see the results of our two methods of calculating sentiment side by side. Assign this merged `DataFrame` to `msft_scores_2010`.\n",
    "3. After the merge, make sure that only articles from 2010 appear and that **the index of the `DataFrame` is the article `id`**.\n",
    "\n",
    "**Note 1:** You need to negate the score of negatively classified articles (indicated by \"N\").\n",
    "\n",
    "**Note 2:** If you run into issues when merging, you may need to reset `full_sentiments` by running the above cell again.\n",
    "\n",
    "**Hint 1:** The articles have a primary key `id`.\n",
    "\n",
    "**Hint 2:** Feel free to reference how you calculated sentiment scores in `q3aii`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "msft_scores_2010.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3c\n",
    "\n",
    "Let's dive deeper into our two methods of calculating sentiment and analyze the accuracy of the method used in `q3b`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 3c, Part i\n",
    "\n",
    "Calculate the difference between `content_sentiment` and `sentence_sentiment`. Create a new column `sentiment_difference` in our `DataFrame` `msft_scores_2010` with `content_sentiment - sentence_sentiment`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "msft_scores_2010['sentiment_difference'] = ...\n",
    "msft_scores_2010.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3ci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 3c, Part ii\n",
    "\n",
    "Below we have provided a plot looking at these differences. Comment on why we see differences when calculating the sentiment of an article as the sentiment of the first sentence mentioning \"microsoft\" or \"msft\" in the article versus the sentiment of the entire article itself. How does context play a role when evaluating the sentiment of a text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(msft_scores_2010['sentiment_difference'])\n",
    "plt.xlabel('Sentiment difference')\n",
    "plt.title('Difference between full and approximate sentiment scores');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Sonia says congratulations! You have finished Homework 4!\n",
    "\n",
    "<img src = \"images/sonia.jpg\" width = \"200\">\n",
    "\n",
    "### Course Content Feedback\n",
    "\n",
    "If you have any feedback about this assignment or about any of our other weekly, weekly assignments, lectures, or discussions, please fill out the [Course Content Feedback Form](https://forms.gle/owfPCGgnrju1xQEA9). Your input is valuable in helping us improve the quality and relevance of our content to better meet your needs and expectations!\n",
    "\n",
    "### Submission Instructions\n",
    "\n",
    "Below, you will see a cell. Running this cell will automatically generate a zip file with your autograded answers. Once you submit this file to the HW 4 Coding assignment on Gradescope, Gradescope will automatically submit a PDF file with your written answers to the HW 4 Written assignment. If you run into any issues when running this cell, feel free to check this [section](https://ds100.org/debugging-guide/autograder_gradescope/autograder_gradescope.html#why-does-grader.exportrun_teststrue-fail-if-all-previous-tests-passed) in the Data 100 Debugging Guide.\n",
    "\n",
    "**Important**: Please check that your written responses were generated and submitted correctly to the HW 4 Written Assignment.\n",
    "\n",
    "**You are responsible for ensuring your submission follows our requirements and that the PDF for HW 4 written answers was generated/submitted correctly. We will not be granting regrade requests nor extensions to submissions that don't follow instructions.** If you encounter any difficulties with submission, please don't hesitate to reach out to staff prior to the deadline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "otter": {
   "OK_FORMAT": true,
   "require_no_pdf_confirmation": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q1a) == 1000\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> q1a.startswith('[{\"id\":46243185,\"title\":\"Ope')\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 'companies such as  Microsoft Corp. ' in q1a\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q1b.upper() in ['A', 'B', 'C', 'D']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> msft_news_df.index.name == 'id'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(['title', 'released_at', 'content', 'path']) == set(msft_news_df.columns)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> msft_news_df.shape == (4635, 4)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.random.seed(100)\n>>> expected = set([10511979, 35357277, 49432195, 52444917, 70540777, 80595106, 86731456, 88502258, 91893641, 97354949])\n>>> set(np.random.choice(sorted(msft_news_df.index), replace=False, size=10)) == expected\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> {'Day', 'Hour', 'Minute', 'Month', 'Second', 'Year'} == set(dates.columns)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(dates['Month'].unique()) == {'April', 'August', 'November', 'December', 'February', 'May', 'October', 'September', 'January', 'June', 'March', 'July'}\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> dates['Year'].dtype == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> dates['Day'].dtype == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> dates['Hour'].dtype == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> dates['Minute'].dtype == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> dates['Second'].dtype == int\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> msft_news_2010.shape == (568, 7)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> msft_news_2010.index.name == 'id'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(msft_news_2010.columns) == {'Day', 'Month', 'Year', 'content', 'path', 'released_at', 'title'}\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2c": {
     "name": "q2c",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> msft_news_df.shape[0] == 4635\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(msft_news_df.columns) == {'amazon', 'apple', 'content', 'facebook', 'netflix', 'nintendo', 'path', 'released_at', 'sony', 'title'}\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2di": {
     "name": "q2di",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> year_news.shape == (4, 6)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(year_news.columns) == {'amazon', 'apple', 'facebook', 'netflix', 'nintendo', 'sony'}\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(year_news.index) == {2010, 2011, 2012, 2013}\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3ai": {
     "name": "q3ai",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> re.findall(microsoft_re, 'the other thing. The capital of seattle is microsoft headquarters. I live near msft! The end.') == [' The capital of seattle is microsoft headquarters.', ' I live near msft!']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> re.findall(microsoft_re, 'hello') == []\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3aii": {
     "name": "q3aii",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 'first_sentence' in msft_news_2010.columns\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type(msft_news_2010['first_sentence'].iloc[0]) == str\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> msft_news_2010.shape == (568, 8)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3aiii": {
     "name": "q3aiii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 'sentence_sentiment' in msft_news_2010.columns\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> msft_news_2010.shape == (568, 9)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(msft_news_2010.columns) == {'Day', 'Month', 'Year', 'content', 'first_sentence', 'path', 'released_at', 'sentence_sentiment', 'title'}\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> msft_news_2010['sentence_sentiment'].iloc[1] <= 1 and msft_news_2010['sentence_sentiment'].iloc[1] >= -1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 'content_sentiment' in msft_scores_2010.columns\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 'sentence_sentiment' in msft_scores_2010.columns\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> msft_scores_2010.index.name == 'id'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3ci": {
     "name": "q3ci",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 'sentiment_difference' in msft_scores_2010.columns\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> msft_scores_2010['sentiment_difference'].iloc[20] <= 2 and msft_scores_2010['sentiment_difference'].iloc[20] >= -2\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
