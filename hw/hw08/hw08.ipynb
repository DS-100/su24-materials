{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c32313",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw08.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c8ae6",
   "metadata": {},
   "source": [
    "# Homework 8: Probability and Estimators\n",
    "## Due Date: Thursday, July 25th, 11:59 PM PT\n",
    "\n",
    "You must submit this assignment to Gradescope by the on-time deadline, Thursday, July 25th, 11:59 PM PT. Please read the syllabus for the grace period policy. No late submissions beyond the grace period will be accepted. **We strongly encourage you to plan to submit your work to Gradescope several hours before the stated deadline.** This way, you will have ample time to reach out to staff for support if you encounter difficulties with submission. While course staff is happy to help guide you with submitting your assignment ahead of the deadline, we will not respond to last-minute requests for assistance (TAs need to sleep, after all!).\n",
    "\n",
    "Please read the instructions carefully when submitting your work to Gradescope.\n",
    "\n",
    "\n",
    "## Content Warning\n",
    "\n",
    "This assignment includes an analysis of daily COVID-19 cases by U.S. county through 2021. If you feel uncomfortable with this topic, **please contact your TA or the instructors.**\n",
    "\n",
    "\n",
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the homework, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625d357f",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38c5ac",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this homework, we will investigate a dataset that contains information about COVID-19 cases in the United States, vaccination rates, and various other metadata that can assist in modeling different aspects of COVID-19.\n",
    "\n",
    "Through this homework assignment, you will demonstrate your experience with:\n",
    "* Bootstrap sampling,\n",
    "* Bias-variance tradeoff and decomposition, and\n",
    "* Multicollinearity in features.\n",
    "\n",
    "## Grading\n",
    "Grading is broken down into auto-graded answers and free responses. \n",
    "\n",
    "For auto-graded answers, the results of your code are compared to provided and/or hidden tests.\n",
    "\n",
    "For free response, readers will evaluate how well you answered the question and/or fulfilled the requirements of the question. \n",
    "\n",
    "### Score breakdown\n",
    "\n",
    "Question | Manual | Points\n",
    "--- |---| ---\n",
    "0 | No | 1\n",
    "1a| No | 3\n",
    "1b| No | 1\n",
    "1c| Yes | 3\n",
    "1d| Yes | 2\n",
    "1e| Yes | 1\n",
    "2a| No | 4\n",
    "2b| Yes |3\n",
    "2c| Yes | 1\n",
    "3a| No | 2\n",
    "3b| No | 4\n",
    "3c| No | 2\n",
    "3d| Yes | 3\n",
    "4a| No | 3\n",
    "4b| Yes | 3\n",
    "4c| No | 2\n",
    "4d| Yes | 2\n",
    "Total | 8 | 40\n",
    "\n",
    "If you run into any technical issues, we highly recommend checking out the [Data 100 Debugging Guide](https://ds100.org/debugging-guide/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c002aad6-f8be-4bbc-a88d-cae054ac512e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 0: Week 6 Check-In\n",
    "\n",
    "Please fill out the following quick, anonymous check-in survey: [LINK](https://forms.gle/ricjE5yuH8tSGQkBA). At the end you will see a secret word, please set `q0` to this secret word as a string. \n",
    "\n",
    "If you fill out the form and forget to take note of the secret word, just click the form link again and you will see the secret word along with a message that you've already filled the form out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d062bec-c92f-4193-963e-90cf790356a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q0 = ...\n",
    "q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065e3e9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae55c9",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 1: Exploratory Data Analysis\n",
    "\n",
    "Let's perform some initial exploratory data analysis to examine and visualize potential trends in a COVID-19 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load the data; no further action is needed.\n",
    "covid_data = pd.read_csv('data/covid_data.csv')\n",
    "covid_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130f947",
   "metadata": {},
   "source": [
    "The data have granularity at the county level; each row corresponds to COVID-19 data from one U.S. county. Here are some highlights and data sources:\n",
    "\n",
    "* The first few columns encode county and state data. Check out the [Federal Information Processing System (FIPS)](https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt) numeric encoding for U.S. counties.\n",
    "* The next 600 columns record daily COVID-19 cases in the county for the date range 1/22/2020 to 9/12/2021. COVID-19 case data are from Center for Systems Sciences and Engineering (CSSE) at Johns Hopkins University [GitHub](https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv).\n",
    "* The next few columns include county populations from [U.S. census data](https://data.census.gov/), the latest of which is 2020.\n",
    "* The last 5 columns record mask usage survey data on a 5-point scale from `NEVER` to `ALWAYS`. The data was collected in July 2020 from the New York Times [GitHub](https://github.com/nytimes/covid-19-data/blob/master/mask-use/mask-use-by-county.csv). Each column represents the proportion of the population in that county who never/rarely/sometimes/frequently/always wear masks. Note, for a particular row, the numbers in those five columns sum up to $1$.\n",
    "\n",
    "We can use `covid_data.describe()` to see various statistics about the numerical features of the provided COVID-19 data. Do any particular statistics stand out to you? Which might be useful when modeling?\n",
    "\n",
    "**Note:** This isn't a question, so it's not worth any points. This is just food for thought as you start to explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3487eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load the data see see statistics of the covid_data\n",
    "covid_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06776ec8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1a\n",
    "\n",
    "In this homework, we will use linear regression to predict **the number of COVID-19 cases  per capita on September 12th, 2021**. Define a column `'9/12/2021_cpc'` in `covid_data` corresponding to **the number of cases per capita** on September 12th, 2021. \n",
    "\n",
    "Note that we will **always** use the `'POPESTIMATE2020'` as the population of each county.\n",
    "\n",
    "*Hint*: The number of cases per capita should be the total number of cases in a county divided by the population of the county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903f696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "covid_data['9/12/2021_cpc'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f750e0fd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2787a6f3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1b\n",
    "\n",
    "Assign `mask_data` to a `DataFrame` with six columns from the original `covid_data` table: the five mask usage columns described earlier and the `9/12/2021_cpc` column.\n",
    "\n",
    "**Note**: You should make a **copy** of these columns using `.copy()` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html)). This ensures that `covid_data` will not change if `mask_data` is modified, and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a3139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_data = ...\n",
    "mask_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48984e7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c56e7e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1c\n",
    "\n",
    "Our goal is to use county-wise mask usage data to predict the number of COVID-19 cases per capita on September 12th, 2021 (i.e., the column `9/12/2021_cpc`). But before modeling, let's do some EDA to explore the multicollinearity in these features, and then we will revisit this in question. \n",
    "\n",
    "Create a visualization that shows the pairwise correlation between each combination of columns in `mask_data`. For 2-D visualizations, consider Seaborn's [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html). Remember to title your plot.\n",
    "\n",
    "**Hint**: You should be plotting 36 values corresponding to the [pairwise correlations](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) of the six columns in `mask_data`. You may optionally set `annot=True`, but it isn't necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7ca49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a25b54",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1d\n",
    "Describe the trends and takeaways visible in the visualization of pairwise correlations you plotted in part (c). Specifically, what does the correlation between pairs of features (i.e., mask usage categories) look like? What does the correlation between mask usage categories and COVID-19 cases per capita look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f68ce38",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800eded6-448a-4837-99da-ce6174dc3ca9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "### Question 1e\n",
    "If we were to build a linear regression model (with an intercept term) using all five mask usage columns as features, what problem would we encounter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade205f",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079491b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 2: Creating a Preliminary COVID-19 Model\n",
    "\n",
    "This question will guide you through creating a linear regression model that will predict the number of COVID-19 cases per capita given various COVID-19 safety protocols that have been implemented. Then, we will investigate the bias, variance, and observational noise of this model in the next two questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ef547",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2a\n",
    "\n",
    "Despite the problems we discussed in the previous question, let's train a linear regression model with an intercept term using `scikit-learn` to predict the number of COVID-19 cases per capita for September 12, 2021, using county-wise mask usage data from `mask_data`. Use `train_test_split` [(documentation)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to evaluate your model's RMSE on a held-out test set with 33% of the COVID-19 data; call the resulting splits `X_train`, `X_test`, `Y_train`, and `Y_test`.\n",
    "\n",
    "To pass the autograder, make sure to set the parameter `random_state` to 42 in your call to `train_test_split` to generate a reproducible data split ([documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525c32c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create train/test sets\n",
    "X = ...\n",
    "Y = ...\n",
    "X_train, X_test, Y_train, Y_test = ...\n",
    "\n",
    "# Fit the linear model and make predictions (you will need multiple lines)\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "# Compute RMSE on train and test sets\n",
    "train_rmse_cpc = ...\n",
    "test_rmse_cpc = ...\n",
    "\n",
    "train_rmse_cpc, test_rmse_cpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36001223",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7823ad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2b\n",
    "\n",
    "To visualize the model performance from part (a), let's make the following two visualizations: \n",
    "1. The observed values vs. the predicted values on the test set.\n",
    "2. The residuals plot (note: in multiple linear regression, the residual plot has the residuals plotted against the predicted values).\n",
    "\n",
    "In both plots, the predicted values should be on the x-axis so that it is easy to make comparisons.\n",
    "\n",
    "**Note:**\n",
    "* We've used `plt.subplot` ([documentation](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html)) so that you can view both visualizations side-by-side. For example, `plt.subplot(121)` sets the plottable area to the first column of a 1x2 plot grid; you can then call `Matplotlib` and `Seaborn` functions to plot that area, before the next `plt.subplot(122)` area is set.\n",
    "* **Remember to add a guiding line to both plots where $\\hat{Y} = Y$, i.e., where the residual is 0**. `plt.plot` and `plt.axhline` might be helpful here!\n",
    "* Consider setting the x-axes of the plots to have the same limits to make it easier to compare the graphs.\n",
    "* Please add descriptive titles and axis labels for your plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce45870d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))      # do not change this line\n",
    "plt.subplot(121)                # do not change this line\n",
    "# 1. plot observations vs. predictions\n",
    "...\n",
    "\n",
    "plt.subplot(122)               # do not change this line\n",
    "# 2. plot residual plot\n",
    "...\n",
    "\n",
    "plt.tight_layout()             # do not change this line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185dd56",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2c\n",
    "\n",
    "Describe what the plots in part (b) indicate about this linear model. In particular, are the predictions good?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa2e02",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0bb3b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 3: Performing Multicollinearity Analysis\n",
    "\n",
    "This question will guide you through performing an analysis that can reveal potential multicollinearity in our features, which is not ideal. In particular, we will use bootstrapping to get $95\\%$ confidence intervals on the fitted parameters. Here's a reminder of the outline of bootstrapping:\n",
    "\n",
    "1. `3a` Assume the sample is a representative sample. We can simulate different samples by resampling from the original sample.\n",
    "2. `3b` Calculate statistic(s) for each resample to simulate different potential result. Statistics can be a mean (Lab 10), correlation (Lab 10), coefficients of a linear model (Question 3 below), and any function of the sample data.\n",
    "3. `3c` Use the distribution of the above statistics calculated on each of the resamples to construct a confidence interval.\n",
    "4. `3d` Use the result of the confidence interval to make an inference of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b26f95",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3a\n",
    "\n",
    "Fill in the blanks below to implement the `bootstrap_sample` function that performs bootstrapping on the given dataset `data` $k$ times. To perform a bootstrap on a `DataFrame` with $n$ rows, randomly draw $n$ samples *with replacement* so that the bootstrapped `DataFrame` is the same size as the original `DataFrame`. The `bootstrap_sample` function should return a list containing $k$ bootstrapped `DataFrames`, each of which has $n$ rows.\n",
    "\n",
    "**Hint**: You may find `df.sample` helpful, see [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html). This is very similar to Lab 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d7436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bootstrap_sample(data, k):\n",
    "    \"\"\"\n",
    "    Performs bootstrap sampling on data to obtain k samples of size n.\n",
    "    \n",
    "    Arguments:\n",
    "        data - Dataset contained as a Pandas DataFrame \n",
    "        k - Number of randomly drawn samples\n",
    "    \n",
    "    Returns:\n",
    "        samples - List containing k Pandas DataFrames of size n each\n",
    "                  corresponding to each sample  \n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "# Print out the first DataFrame only\n",
    "bootstrap_sample(mask_data, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb9fe24",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c545e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3b\n",
    "\n",
    "Using the function from the previous part, let's do the following:\n",
    "\n",
    "1. Generate 1000 bootstrapped samples from the original `mask_data` `DataFrame`. \n",
    "2. For each of the 1000 bootstrapped samples, use `sklearn` to fit a linear regression model (with an intercept term) like we did in Question 2, where mask usage categories are the features and `9/12/2021_cpc` is the response. You should fit 1000 models in total. \n",
    "3. Store each of the 1000 trained models in the `models` list.\n",
    "\n",
    "**Hint:**\n",
    "* You *should not* create any validation or testing sets in this subpart; each model should fit to one entire bootstrapped `DataFrame`.\n",
    "* `LinearRegression` is an object type; to store a new model you must create a new instance first!\n",
    "* Do not use `X` and `Y` as variable names while bootstrapping as this will override the values stored in `q2a`.\n",
    "* When fitting each model, remember that your design matrix should be a 2D array or `pandas` `DataFrame` whereas the true labels should be a `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1b10b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42) # DO NOT REMOVE THIS LINE\n",
    "\n",
    "datasets = ...\n",
    "models = []\n",
    "...\n",
    "\n",
    "\n",
    "# Datasets take up a lot of memory, so we should remove them!\n",
    "del datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a7c8f6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754713cc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3c\n",
    "\n",
    "Fill in the blanks below in the `confidence_interval` function to generate a $95\\%$ confidence interval for each of our parameters $\\theta_i$, including the intercept term $\\theta_0$. All of the helper code to extract coefficients from our trained models has been implemented for you already.\n",
    "\n",
    "**Hint**: \n",
    "- For a refresher on confidence intervals, refer to this section in the [Data 8 textbook](https://inferentialthinking.com/chapters/13/3/Confidence_Intervals.html). \n",
    "- Pay close attention to how the arrays used below are formatted. What does each row represent? What does each column represent? To get the $i$th column from a 2D-array, you can use `2D_array[:, i]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b3e47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_coefs(models, include_intercept = True):\n",
    "    \"\"\"\n",
    "    NOTE: This function has already been implemented. You do not need to modify this!\n",
    "    \n",
    "    Extracts coefficients of all the linear regression models in MODELS and returns\n",
    "    it as a NumPy array with one model's coefficients as each row.\n",
    "    \n",
    "    Arguments:\n",
    "        models - Contains k sklearn LinearRegression models, each with p + 1 coefficients.\n",
    "        include_intercept - Whether to include an intercept in returned coefficients.\n",
    "    \n",
    "    Returns:\n",
    "        coef_array - Coefficients of all k models, each with p + 1 coefficients (if intercept\n",
    "                     enabled, otherwise p). The returned object is k x (p + 1) NumPy array.\n",
    "    \"\"\"\n",
    "    coef_array = np.zeros(shape = (len(models), len(models[0].coef_) + 1))\n",
    "    for i, m in enumerate(models):\n",
    "        coef_array[i, 0] = m.intercept_\n",
    "        coef_array[i, 1:] = m.coef_\n",
    "    if include_intercept:\n",
    "        return coef_array \n",
    "    return coef_array[:, 1:]\n",
    "\n",
    "def confidence_interval(coefs):\n",
    "    \"\"\"\n",
    "    Calculates confidence intervals for each theta_i based on coefficients of \n",
    "    bootstrapped models. Returns output as a list of confidence intervals.\n",
    "    \n",
    "    Arguments:\n",
    "        coefs - Output of extract_coefs, a k x (p + 1) or k x p NumPy array containing\n",
    "                coefficients of bootstrapped models.\n",
    "    \n",
    "    Returns:\n",
    "        cis - Confidence intervals of each parameter theta_i in the form of a \n",
    "              list like this: [(0.5, 0.75), (0.2, 0.4), ...].\n",
    "    \"\"\"\n",
    "    cis = []\n",
    "    \n",
    "    # FILL IN CODE BELOW\n",
    "    for i in range(...):\n",
    "        theta_i_values = ...\n",
    "        theta_i_lower_ci, theta_i_upper_ci = np.percentile(...), np.percentile(...)\n",
    "        cis.append((theta_i_lower_ci, theta_i_upper_ci))\n",
    "    \n",
    "    return cis\n",
    "\n",
    "\n",
    "# Compute confidence intervals\n",
    "model_coefs = extract_coefs(models)\n",
    "cis = confidence_interval(model_coefs)\n",
    "\n",
    "# Pretty print in a table\n",
    "display(Markdown('#### Confidence Intervals:'))\n",
    "md_list = [\"|parameter|lower|upper|\",\n",
    "           \"----|----|----|\"]\n",
    "md_list += [fr\"|$\\theta_{i}$|{lci}|{uci}|\" for i, (lci, uci) in enumerate(cis)]\n",
    "display(Markdown('\\n'.join(md_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb45a6f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f472257c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3d\n",
    "\n",
    "Interpret the confidence intervals above for each of the $\\theta_i$, where $\\theta_0$ is the intercept term, and the remaining $\\theta_i$'s are parameters corresponding to mask usage features. How does this relate to your observations in `q1d`, and what does that indicate about the usefulness of all the features for your model?\n",
    "\n",
    "Hint: The lecture or [course notes](https://ds100.org/course-notes/inference_causality/inference_causality.html) discussing collinearity might be a useful starting point when approaching this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43012b3d",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d20bd06-2331-4537-8fe6-9bf92cc8cfcc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 4: Performing Bias-Variance Analysis\n",
    "\n",
    "This question will guide you through performing an analysis that can estimate the bias and variance of our models, which can be helpful in modeling.\n",
    "\n",
    "Recall that the **model variance** on a data point $\\vec{x_k}$ is simply the variance of our predictions on that sample point $\\vec{x_k}$. \n",
    "\n",
    "$$\\text{model variance} = \\mathrm{Var}(\\hat{Y}(\\vec{x_k})) = \\mathrm{Var}(\\vec{x_k}^T\\hat{\\theta})$$\n",
    "\n",
    "Since we are using OLS, we can also rewrite our model as $\\hat{Y}(\\vec{x_k}) = \\vec{x_k}^T\\hat{\\theta} = \\hat{\\theta_0} 1 + \\hat{\\theta_1}x_{k, 1} + ... + \\hat{\\theta_p}x_{k, p}$. To estimate the model variance, we can sample a particular data point $(\\vec{x_k}, y_k)$ and calculate the variance of the predictions using different fitted models in `models`. Note that the variance is taken across different models $\\hat{Y}(\\vec{x_k})$, which are pre-selected and fixed. \n",
    "\n",
    "Also, recall that **model risk** for this point is the same as the mean square error over all possible fitted models:\n",
    "\n",
    "$$\n",
    "\\text{model risk} = \\mathbb{E}\\left[\\left(y_k - \\hat{Y}(\\vec{x_k}) \\right)^2\\right] \\approx \\frac{1}{\\# \\text{ of bootstrap}}\\sum_{j=1}^{\\# \\text{ of bootstrap}} (y_k - \\hat{Y}_j(\\vec{x_k}))^2 = MSE(\\vec{x_k})\n",
    "$$\n",
    "\n",
    "where the subscript $j$ is used to denote different models. Here, we are considering a particular observation of the random response variable $y_k$. Therefore model risk is an expectation over the estimate $\\hat{\\theta}_j$, coefficients corresponding to different models. $\\hat{\\theta}_j$ itself is a random variable because it was derived by fitting to different random resamples. We can also find the ratio of model variance to model risk. You can interpret this ratio as the proportion of the expected square error on the data point \"captured\" or \"explained\" by the model variance: \n",
    "\n",
    "$$\n",
    "\\frac{\\text{model variance}}{\\text{model risk}}=\\frac{\\mathrm{Var}(\\hat{Y}(\\vec{x_k}))}{\\mathbb{E}\\left[\\left(y_k - \\hat{Y}(\\vec{x_k}) \\right)^2\\right]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4302f9fe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4a\n",
    "\n",
    "Let's use the last row of our design matrix `X` and its corresponding `Y` value to find these quantities! Recall we defined `X` and `Y` back in Question `2a`, which is what you should be referencing here.\n",
    "\n",
    "Complete the function `simulate` that takes in a data point `xk`, `yk` and returns `model_risk`, `model_var`, and `ratio`, the ratio of model variance to model risk.\n",
    "\n",
    "Here is a suggested format, but you do not need to follow the skeleton code:\n",
    "* Assign `predictions` to a length 1000 vector where each element is the prediction on `xk` using a model in `models`. Note that `sklearn`'s `.predict` returns an array, but we only need a **scalar prediction**! Try to print out a prediction and adjust your code if needed.\n",
    "* Use `predictions` to compute the estimated `model_risk`.\n",
    "* Use `predictions` to compute the estimated `model_var`.\n",
    "* Use `model_risk` and `model_var` to compute the `ratio`, the ratio of model variance to model risk.\n",
    "\n",
    "**Hint**: You can use list comprehension for creating your predictions to save yourself the overhead of using multiple appends, as well as `np.mean` and `np.var` for computing means and variances of an array or list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c888da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate(xk, yk, models):\n",
    "    predictions = ...\n",
    "    model_risk = ...\n",
    "    model_var = ...\n",
    "    ratio = ...\n",
    "    return model_risk, model_var, ratio\n",
    "x_last = ...\n",
    "y_last = ...\n",
    "model_risk, model_var, ratio = simulate(x_last, y_last, models)\n",
    "model_risk, model_var, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c5df1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2474933",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4b\n",
    "\n",
    "Comment on the ratio `ratio`, which is the proportion of the expected square error on the data point captured by the model variance. Is the model variance the dominant term in the bias-variance decomposition? If not, what term(s) dominate the bias-variance decomposition?\n",
    "\n",
    "**Note**: The Bias-Variance decomposition from the lecture is:\n",
    "\n",
    "$$\n",
    "\\text{model risk} = \\sigma^2 + (\\text{model bias})^2 + \\text{model variance}\n",
    "$$\n",
    "\n",
    "where $\\sigma^2$ is the observation variance, or \"irreducible error\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3a45b",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65ab4d8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4c\n",
    "\n",
    "Now let's calculate the average variance and average mean squared error across 250 randomly sampled $(x_i, y_i)$ points. In other words, estimate the following quantities across all $x_i$ and $y_i$ in `X_sample` and `Y_sample`:\n",
    "\n",
    "* Average variance is given by: $$\\frac{1}{250} \\sum_{k=1}^{250} \\mathrm{Var}\\left(\\hat{Y}(\\vec{x_k})\\right)$$\n",
    "* Average mean squared error is given by: $$\\frac{1}{250} \\sum_{k=1}^{250} \\mathbb{E}\\left[ (y_k - \\hat{Y}(\\vec{x_k}))^2 \\right]$$\n",
    "\n",
    "**Hint:** Call `simulate` from `q4a`.\n",
    "\n",
    "Note that this question may take a little longer to run than usual. However, if your code runs for more than ~10 minutes, please reassess your code in `q4a` and `q4c`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0657927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_sample = X.sample(250)         # Generate 250 x_i\n",
    "Y_sample = Y.loc[X_sample.index] # and select the corresponding y_i\n",
    "\n",
    "var, mse = [], []\n",
    "\n",
    "# Write your code to calculate the variances and MSEs below\n",
    "...\n",
    "\n",
    "avg_var, avg_mse = np.mean(var), np.mean(mse)\n",
    "avg_var, avg_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8c85b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1458361f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4d\n",
    "\n",
    "Propose a method of reducing the mean square error using the insights gained from the bias-variance decomposition above.\n",
    "\n",
    "Assume that the standard bias-variance decomposition used in lecture can be applied here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc7d36",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076c0b07",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Congratulations! You have finished Homework 8!\n",
    "\n",
    "Here are some cats :) Can you find their names? There are two ways you can find them on JupyterLab.\n",
    "\n",
    "<img src=\"images/Pandas.jpg\" width=\"370px\"/> <img src=\"images/Patches.jpg\" width=\"200px\" /> <img src=\"images/Pishi.jpg\" width=\"208px\" />\n",
    "\n",
    "\n",
    "### Course Content Feedback\n",
    "\n",
    "If you have any feedback about this assignment or about any of our other weekly assignments, lectures, or discussions, please fill out the [Course Content Feedback Form](https://forms.gle/owfPCGgnrju1xQEA9). Your input is valuable in helping us improve the quality and relevance of our content to better meet your needs and expectations!\n",
    "\n",
    "### Submission Instructions\n",
    "\n",
    "Below, you will see a cell. Running this cell will automatically generate a zip file with your autograded answers. Once you submit this file to the Homework 8 Coding assignment on Gradescope, Gradescope will automatically submit a PDF file with your written answers to the Homework 8 Written assignment. If you run into any issues when running this cell, feel free to check this [section](https://ds100.org/debugging-guide/autograder_gradescope/autograder_gradescope.html#why-does-grader.exportrun_teststrue-fail-if-all-previous-tests-passed) in the Data 100 Debugging Guide.\n",
    "\n",
    "**Important**: Please check that your **plots/graphs and written responses** were generated and submitted correctly to the Homework 8 Written Assignment.\n",
    "\n",
    "**You are responsible for ensuring your submission follows our requirements and that the PDF for Homework 8 written answers was generated/submitted correctly. We will not be granting regrade requests nor extensions to submissions that don't follow instructions.** If you encounter any difficulties with submission, please don't hesitate to reach out to staff prior to the deadline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0158b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a9c481",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e7f67",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "otter": {
   "OK_FORMAT": true,
   "require_no_pdf_confirmation": true,
   "tests": {
    "q0": {
     "name": "q0",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(q0) == str\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1a": {
     "name": "q1a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(covid_data['9/12/2021_cpc'].iloc[0], 0.16541098940244012)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(covid_data['9/12/2021_cpc'].sum(), 397.68435739730006)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> mask_data.shape == (3141, 6) or mask_data.shape == (3141, 7)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(mask_data.columns) == set(['NEVER', 'RARELY', 'SOMETIMES', 'FREQUENTLY', 'ALWAYS', '9/12/2021_cpc'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(mask_data['NEVER'].sum(), 251.13)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> mask_data._is_view == False\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X.equals(mask_data[['NEVER', 'RARELY', 'SOMETIMES', 'FREQUENTLY', 'ALWAYS']])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> Y.equals(mask_data['9/12/2021_cpc'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 0.01 <= train_rmse_cpc <= 0.05\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 0.01 <= test_rmse_cpc <= 0.05\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> all([len(df_i) == len(mask_data) for df_i in bootstrap_sample(mask_data, 1)])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> len(bootstrap_sample(mask_data, 3)) == 3\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(bootstrap_sample(mask_data, 1)[0]['NEVER'].mean(), 0.0799, atol=0.008)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X.equals(mask_data[['NEVER', 'RARELY', 'SOMETIMES', 'FREQUENTLY', 'ALWAYS']])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> Y.equals(mask_data['9/12/2021_cpc'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> len(models) == 1000\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all([isinstance(model, lm.LinearRegression) for model in models])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all([len(model.coef_) == 5 and model.intercept_ != 0 for model in models])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(models[0].coef_ != models[1].coef_)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c": {
     "name": "q3c",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(cis) == 6 and all((len(ci) == 2 for ci in cis))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all([lci < 0 and uci > 0 for lci, uci in cis])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> model_risk <= 0.003\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> model_var <= 1e-05\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(ratio, 0.006397075186207152, atol=0.001)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4c": {
     "name": "q4c",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> avg_var <= 1e-05\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> avg_mse <= 0.005\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
