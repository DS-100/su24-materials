{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177aa181",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw10.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae3b41-b7fb-4739-91f3-1e7c773789b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "# Homework 10:  PCA and Decision Trees\n",
    "## Due Monday, August 5th, 11:59 PM PT\n",
    "\n",
    "In this assignment, we will use PCA to analyze a dataset on presidential elections, then we will build and evaluate decision trees on a dataset of NBA players.\n",
    "\n",
    "As we are nearing the end of the summer, this assignment is an **optional, extra-credit homework**. Students skipping this assignment will not lose homework points, while students completing this assignment will receive extra credit equivalent to the point value of a normal homework assignment. Also note that for this assignment, **free response questions will be graded on completion and coherence**. Since we are approaching the end of the course and have limited time for grading, you will receive full credit on free response questions as long as your answers demonstrate effort.\n",
    "\n",
    "You must submit this assignment to Gradescope by the on-time deadline, Monday, August 5th, 11:59 PM PT. Please read the syllabus for the grace period policy. No late submissions beyond the grace period will be accepted. **We strongly encourage you to plan to submit your work to Gradescope several hours before the stated deadline.** This way, you will have ample time to reach out to staff for support if you encounter difficulties with submission. While course staff is happy to help guide you with submitting your assignment ahead of the deadline, we will not respond to last-minute requests for assistance (TAs need to sleep, after all!).\n",
    "\n",
    "Please read the instructions carefully when submitting your work to Gradescope.\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the homework, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034ab031-c2d8-4be3-9e17-78885f93c755",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8d420-1c33-4efe-9c2a-5f84a975cb4b",
   "metadata": {},
   "source": [
    "## Grading\n",
    "Grading is broken down into autograded answers and free response. As noted above, for this assignment free response questions will be graded based on completion and coherence.\n",
    "\n",
    "<!--\n",
    "<details>\n",
    "    <summary>[Click to Expand] <b>Scoring Breakdown</b></summary>-->\n",
    "|Question|Points|\n",
    "|---|---|\n",
    "|1a | 1 |\n",
    "|1b | 1 |\n",
    "|1c | 1 |\n",
    "|1d | 1 |\n",
    "|1e | 1 |\n",
    "|2a | 1 |\n",
    "|2b | 1 |\n",
    "|3a | 1 |\n",
    "|3b | 1 |\n",
    "|3c | 1 |\n",
    "|4a | 1 |\n",
    "|4b | 1 |\n",
    "|4c | 1 |\n",
    "|5a | 1 |\n",
    "|5b | 1 |\n",
    "|5c | 1 |\n",
    "|5d | 1 |\n",
    "|Total | 17 |\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c507d6f2-9d14-4110-8b5c-ea93ff25027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import sqlalchemy\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "# You may get a warning from importing ensemble. It is OK to ignore this warning.\n",
    "from sklearn import ensemble\n",
    "\n",
    "plt.style.use('fivethirtyeight') # Use plt.style.available to see more styles\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "np.set_printoptions(threshold=5) # avoid printing out big matrices\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9124d9-c112-4c49-b6db-53f08d93bf86",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# PCA: U.S. Presidential Elections By State\n",
    "\n",
    "First, we'll start off with PCA on a real-world dataset. If you haven't worked with Principal Component Analysis before, we highly encourage you to take a look at the PCA lab first. PCA really shines on data where you have reason to believe that the data is relatively low in rank. \n",
    "\n",
    "We'll look at how states voted in presidential elections between 1972 and 2016. **Our ultimate goal is to show how 2D PCA scatterplots can allow us to identify clusters in a high dimensional dataset.** For this example, that means finding groups of states that vote similarly by plotting their 1st and 2nd principal components.\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 1\n",
    "\n",
    "We explore a dataset on U.S. Presidential Elections by State since 1789, as taken from [Wikipedia](https://en.wikipedia.org/wiki/List_of_United_States_presidential_election_results_by_state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab6eef-e424-46df-b71c-953b74b762d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/presidential_elections.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60f105a-3d6d-4c7b-95f1-4f60ad6ccdea",
   "metadata": {},
   "source": [
    "The data in this table is pretty messy (missing records, inconsistent field naming, etc.), so let's create a clean version.\n",
    "\n",
    "Running the cell below will produce a clean table, which contains exactly 51 rows (corresponding to the 50 states plus Washington DC) and 13 columns (one for each of the election years from 1972 to 2020). The index of this dataframe is the state name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e8eb9-42f8-46a2-808e-0439f98d491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "df_clean = ( \n",
    "        df.iloc[:, -15:]    \n",
    "        .drop(['Unnamed: 60'], axis = 1) \n",
    "        .rename(columns = {\"2000 ‡\": \"2000\", \"2016 ‡\": \"2016\", \"State.1\": \"State\"}) \n",
    "        .drop([51]) \n",
    "        .set_index(\"State\")\n",
    ")\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9185ed3-5ac9-4ab2-9def-5ee0427d8408",
   "metadata": {},
   "source": [
    "Side note: We produced the data cleaning function chain above by inspecting the CSV file. In your personal projects, you may be tempted to use Excel or Google Sheets (What You See Is What You Get, or WYSIWYG) to clean data. While sometimes more convenient, the downside of this is that you have no record of what you did—and if you have to redownload the data, you have to redo the manual data cleaning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4bd991-b307-42c2-8161-8b5a154e4d27",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 1a\n",
    "\n",
    "What does each row in `df_clean` represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d200b6e5",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae25df18-03e3-454d-8b28-0d03bab23a01",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 1b\n",
    "\n",
    "To perform PCA, we need to convert our data into numerical values. Create a `df_numerical` dataframe that replaces all of the \"D\" characters in `df_clean` with the number 0, and all of the \"R\" characters with the number 1. \n",
    "\n",
    "*Hint:* Use `df.replace` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97604143-7bf4-4f7c-9a7a-1508d97f06dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_numerical = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb98b7f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5fba2e-6a4c-47bd-9813-46095e29af2f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 1c\n",
    "\n",
    "Now **standardize the data**: Center the data so that each column's mean is 0, and scale the data so that each column's variance is 1. Store your result in `df_standardized`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037dcfe3-9570-4d26-8b92-5c060221c382",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_standardized = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983711a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2f866-e111-4909-b476-5400558dba66",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "We now have our data in a nice and tidy centered and scaled format. Phew! We are now ready to do PCA.\n",
    "\n",
    "<br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 1d: SVD\n",
    "\n",
    "In the following cell, compute the SVD of `df_standardized`:\n",
    "\n",
    "$$\\texttt{df}\\_\\texttt{standardized}=U S V^{T}$$\n",
    "\n",
    "\n",
    "Store the $U$, $S$, and $V^T$ matrices in `u`, `s`, and `vt` respectively. This is one line of simple code (exactly like what we saw in lecture and what you did in lab) using the [`np.linalg.svd`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html) function with the `full_matrices` argument set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f03c2b8-1ea4-4eaf-a52b-57dc238fbca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "u, s, vt = ...\n",
    "u, s, vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09226e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b03b1a-f229-460a-beae-f8982f69bb41",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 1e: Get Principal Components\n",
    "\n",
    "Using your results from the previous part, create a new `first_2_pcs` **dataframe** ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)) that contains exactly the first two columns of the principal components matrix. The first column should be labeled `pc1` and the second column should be labeled `pc2`. Store your result in `first_2_pcs`, and make sure to set the index to be the default numerical range index (i.e. 0, 1, 2, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166510f6-ad8a-45f9-a5ad-6345f2897437",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_2_pcs = ...\n",
    "first_2_pcs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af5dc14",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bcace8-578d-4d97-941d-6000c7945bcd",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 2\n",
    "\n",
    "The cell below plots the 1st and 2nd principal components of our 50 states + Washington DC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97208dbb-0771-4818-af40-be6ed423a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "sns.scatterplot(data = first_2_pcs, x = \"pc1\", y = \"pc2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322da1f1-634e-45c8-b66b-6f09896b561c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Unfortunately, we have two problems:\n",
    "\n",
    "1. There is a lot of overplotting, with only 28 distinct dots (out of 104 points). This means that at least some states voted exactly alike in these elections.\n",
    "2. We don't know which state is which because the points are unlabeled.\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 2a: Jitter\n",
    "\n",
    "Let's start by addressing problem 1. \n",
    "\n",
    "**In the cell below, create a new dataframe `first_2_pcs_jittered` with a small amount of random noise added to each principal component. In this same cell, create a scatterplot.**\n",
    "\n",
    "To reduce overplotting, we **jitter** the first two principal components:\n",
    "* Add a small amount of random, unbiased Gaussian noise to each value using `np.random.normal` ([documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)) with mean 0 and standard deviation less than 1.\n",
    "* Don't get caught up on the exact details of your noise generation; it's fine as long as your plot looks roughly the same as the original scatterplot, but without overplotting.\n",
    "* The amount of noise you add *should not significantly affect* the appearance of the plot; it should simply serve to separate overlapping observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834341e-66ed-455b-888c-0121872930ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first, jitter the data\n",
    "first_2_pcs_jittered = ...\n",
    "\n",
    "# then, create a scatter plot\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fcc382-5cb5-4d29-a66a-73c347bcd36b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 2b\n",
    "\n",
    "To address Problem 2, we can turn to Plotly. The below cell uses these Plotly guides ([example 1](https://plot.ly/python/text-and-annotations/), [example 2](https://plotly.com/python/hover-text-and-formatting/#disabling-or-customizing-hover-of-columns-in-plotly-express)) to create a scatter plot of the jittered ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116119f7-c516-459d-af4c-7ffabd319786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "import plotly.express as px\n",
    "\n",
    "# get the state names from the standardized dataframe's index\n",
    "first_2_pcs_jittered['state'] = df_standardized.index\n",
    "\n",
    "# show state names on hover\n",
    "fig = px.scatter(first_2_pcs_jittered, x=\"pc1\", y=\"pc2\",\n",
    "                hover_data={\"state\": True}); \n",
    "\n",
    "fig.show(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f26ca-1032-4dc0-8e81-7bd2da5727cf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Analyze the above plot. In the below cell, address the following two points:\n",
    "1. Give an example of a cluster of states that vote a similar way. Does the composition of this cluster surprise you? If you're not familiar with U.S. politics, it's fine to just say \"No, I'm not surprised because I don't know anything about U.S. politics.\"\n",
    "1. Include anything interesting that you observe. You will get credit for this as long as you write something reasonable that you can takeaway from the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c7a2b",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c42a0f2-a510-49ee-86cf-dd7c2f42ef57",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 3\n",
    "\n",
    "We can also look at the contributions of each year's elections results on the values for our principal components.\n",
    "\n",
    "Below, we define the `plot_pc` function that plots and labels the rows of $V^T$. We then call this function to plot the 1st row of $V^T$, i.e., the row of $V^T$ that corresponds to `pc1`.\n",
    "\n",
    "**Note**: If you get an error when running this cell, make sure you are properly assigning the `vt` variable from Question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec9e97-d17d-46ad-b48e-7b426947f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "\n",
    "def plot_pc(col_names, row_mat_vt, k):\n",
    "    plt.bar(col_names, row_mat_vt[k, :], alpha=0.7)\n",
    "    plt.xticks(col_names, rotation=90);\n",
    "    \n",
    "plt.figure(figsize=(12, 4)) # adjusts size of plot\n",
    "plot_pc(list(df_standardized.columns), vt, 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba7314-c61c-43a2-80c5-ac8cf4919cad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 3a\n",
    "\n",
    "In the cell below, plot the the 2nd row of $V^T$, i.e., the row of $V^T$ that correpsonds to `pc2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c9ea9b-1681-484f-975f-d92642d1e7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a91f691-c040-4d8e-9dea-79e8a6727536",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 3b\n",
    "\n",
    "Using the two above plots of the rows of $V^T$ as well as the original table, give a description of what it means for a point to be in the top-right quadrant of the 2-D scatter plot from Question 2.\n",
    "\n",
    "In other words, what is generally true about a state with relatively large positive value for `pc1` (right side of 2-D scatter plot)? For a large positive value for `pc2` (top side of 2-D scatter plot)?\n",
    "\n",
    "Notes:\n",
    "* `pc2` is pretty hard to interpret, and the staff doesn't really have a consensus on what it means either - there is no correct answer necessarily. \n",
    "* Principal components beyond the first are often hard to interpret (but not always; see the lab)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca19d4",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fbc02b-dfba-4e14-b113-159122c2767e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# feel free to use this cell for scratch work. If you need more scratch space, add cells *below* this one.\n",
    "\n",
    "# Make sure to put your actual answer in the cell above where it says \"Type your answer here, replacing this text\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1e22d-092e-4ba8-aee8-8c40df5bc32e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 3c\n",
    "\n",
    "To get a better sense of whether our 2D scatterplot captures the whole story, create a **scree plot** for this data. In other words, plot the fraction of the total variance (y-axis) captured by the ith principal component (x-axis).\n",
    "\n",
    "*Hint:* Be sure to label your axes appropriately! You may find `plt.xticks()` ([documentation](https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.xticks.html)) helpful for formatting. Also check out the lab for more on scree plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a132fd-f0f2-43d1-95ad-05be0aa51b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6ccc33-8f4e-4911-b5d4-09eba2a696da",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "From your scree plot above, you should see that the first two principal components capture a large portion of the variance in our cleaned data. It is partially for this reason that the 2D scatter plot of principal components was easy to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db9b2a8-0744-4338-9065-d4f9c84951da",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Decision Trees\n",
    "\n",
    "Now, we'll be switching gears to try out building decision trees on a different dataset. We will have you train a multi-class classifier with three different models (one-vs-rest logistic regression, decision trees, random forests) and compare the accuracies and decision boundaries created by each. \n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "## [Tutorial] Dataset, EDA, and Classification Task\n",
    "We'll be looking at a dataset of per-game stats for all NBA players in the 2018-19 season. This dataset comes from [basketball-reference.com](https://www.basketball-reference.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d230b-b904-48b3-ac49-0822edd648f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "\n",
    "nba_data = pd.read_csv(\"data/nba18-19.csv\")\n",
    "nba_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b6847-8695-4329-ad7f-7c141c4b751e",
   "metadata": {},
   "source": [
    "Our goal will be to predict a player's **position** given several other features. The 5 positions in basketball are PG, SG, SF, PF, and C (which stand for point guard, shooting guard, small forward, power forward, and center; [Wikipedia](https://en.wikipedia.org/wiki/Basketball_positions)).\n",
    "\n",
    "This information is contained in the `Pos` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5416533c-25d8-4c4b-a258-a5a4c36e9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_data['Pos'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199cc62e-0a84-4997-a027-feb133cd6455",
   "metadata": {},
   "source": [
    "There are several features we could use to predict this position; check the [Basketball statistics](https://en.wikipedia.org/wiki/Basketball_statistics) page of Wikipedia for more details on the statistics themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d2beb4-c0ae-4f2e-92cb-28ff8216e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a758f-c6e7-4882-aebf-07cf41846206",
   "metadata": {},
   "source": [
    "In this lab, we will restrict our exploration to two inputs: [Rebounds](https://en.wikipedia.org/wiki/Rebound_(basketball)) (`TRB`) and [Assists](https://en.wikipedia.org/wiki/Assist_(basketball)) (`AST`). Two-input feature models will make our 2-D visualizations more straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3715bf-5eea-413c-ab4a-2ffe42b9051d",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### 3-class classification\n",
    "\n",
    "While we could set out to try and perform 5-class classification, the results (and visualizations) are slightly more interesting if we try and categorize players into 1 of 3 categories: **Guard**, **Forward**, and **Center**. The below code will take the `Pos` column of our dataframe and use it to create a new column `Pos3` that consist of values `'G'`, `'F'`, and `'C'` (which stand for Guard, Forward, and Center)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32550f29-5d3f-4478-9ad3-2b8ec27f7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "def basic_position(pos):\n",
    "    if 'F' in pos:\n",
    "        return 'F'\n",
    "    elif 'G' in pos:\n",
    "        return 'G'\n",
    "    return 'C'\n",
    "\n",
    "nba_data['Pos3'] = nba_data['Pos'].apply(basic_position)\n",
    "nba_data['Pos3'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ff0df-4364-4d9d-826e-37b6f78ebe02",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "### Data Cleaning and Visualization\n",
    "\n",
    "Furthermore, since there are **many** players in the NBA (in the 2018-19 season there were 530 unique players), our visualizations can get noisy and messy. Let's restrict our data to only contain rows for players that averaged 10 or more points per game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781d3c98-1f77-40e2-b8b7-d3f8fb33d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "nba_data = nba_data[nba_data['PTS'] > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098982db-be08-4aa3-9ecb-6cc5c6a7ddd6",
   "metadata": {},
   "source": [
    "Now, let's look at a scatterplot of Rebounds (`TRB`) vs. Assists (`AST`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05ed10-ea54-40a1-8c6d-6983d7a056d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = nba_data, x = 'AST', y = 'TRB', hue = 'Pos3');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f1fd1a-b1ed-490a-9aa7-f94a293dcbf0",
   "metadata": {},
   "source": [
    "As you can see, when using just rebounds and assists as our features, we see pretty decent cluster separation. That is, Guards, Forward, and Centers appear in different regions of the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76559848-47c2-4643-b3cd-ea1a72280cf3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 4: Evaluating Split Quality\n",
    "\n",
    "We will explore different ways to evaluate split quality for classification trees in this question.\n",
    "\n",
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4a: Entropy\n",
    "\n",
    "In lecture we defined the entropy $S$ of a node as:\n",
    "\n",
    "$$ S = -\\sum_{C} p_C \\log_{2} p_C $$\n",
    "\n",
    "where $p_C$ is the proportion of data points in a node with label $C$. This function is a measure of the unpredictability of a node in a decision tree. \n",
    "\n",
    "Implement the `entropy` function, which outputs the entropy of a node with a given set of labels. The `labels` parameter is a list of labels in our dataset. For example, `labels` could be `['G', 'G', 'F', 'F', 'C', 'C']`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc355fd-1989-4022-9906-c39af041f02b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    ...\n",
    "\n",
    "entropy(nba_data['Pos3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee9f28",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934e1a68-e64f-4a0c-9876-cc08531e76b3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4b: Gini impurity\n",
    "\n",
    "Another metric for determining the quality of a split is **Gini impurity**. This is defined as the chance that a sample would be misclassified if randomly assigned at this point. Gini impurity is a popular alternative to entropy for determining the best split at a node, and it is in fact the default criterion for scikit-learn's `DecisionTreeClassifier`.\n",
    "\n",
    "We can calculate the Gini impurity of a node with the formula ($p_C$ is the proportion of data points in a node with label $C$):\n",
    "\n",
    "$$ G = 1 - \\sum_{C} {p_C}^2 $$\n",
    "\n",
    "Note that no logarithms are involved in the calculation of Gini impurity, which can make it faster to compute compared to entropy.\n",
    "\n",
    "Implement the `gini_impurity` function, which outputs the Gini impurity of a node with a given set of labels. The `labels` parameter is defined similarly to the previous part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2bccd-6ab7-448a-9fa4-6498774d0768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gini_impurity(labels):\n",
    "    ...\n",
    "\n",
    "gini_impurity(nba_data['Pos3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c8535",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539ca73-5dba-4b21-be2d-349053c26f7f",
   "metadata": {},
   "source": [
    "As an optional exercise in probability, try to think of a way to derive the formula for Gini impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93dacbd-2c86-40e6-8ebe-14b1c53acca0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4c: Weighted Metrics\n",
    "\n",
    "In lecture, we used **weighted entropy** as a loss function to help us determine the best split. Recall that the weighted entropy is given by:\n",
    "\n",
    "$$ L = \\frac{N_1 S(X) + N_2 S(Y)}{N_1 + N_2} $$\n",
    "\n",
    "$N_1$ is the number of samples in the left node $X$, and $N_2$ is the number of samples in the right node $Y$. This notion of a weighted average can be extended to other metrics such as Gini impurity simply by changing the $S$ (entropy) function to $G$ (Gini impurity).\n",
    "\n",
    "First, implement the `weighted_metric` function. The `left` parameter is a list of labels or values in the left node $X$, and the `right` parameter is a list of labels or values in the right node $Y$. The `metric` parameter is a function which can be `entropy` or `gini_impurity`. For `entropy` and `gini_impurity`, you may assume that `left` and `right` contain discrete labels.\n",
    "\n",
    "Then, assign `we_pos3_age_30` to the weighted entropy (in the `Pos3` column) of a split that partitions `nba_data` into two groups: a group with players who are 30 years old or older and a group with players who are younger than 30 years old.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc169308-8076-4eed-8212-0bd0afdc4991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_metric(left, right, metric):\n",
    "    ...\n",
    "\n",
    "we_pos3_age_30 = ...\n",
    "we_pos3_age_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf31ec",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a68e4f-4bb7-480f-bc5d-ac4e66100a41",
   "metadata": {},
   "source": [
    "We will not go over the entire decision tree fitting process in this assignment, but you now have the basic tools to fit a decision tree. As an optional exercise, try to think about how you would extend these tools to fit a decision tree from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30033c16-a36f-4a1d-a508-5c03736bd27c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 5: Classification\n",
    "\n",
    "Before fitting any models, let's first split `nba_data` into a training set and test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c02e8-8924-46da-a438-a3b71c5dbe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "nba_train, nba_test = train_test_split(nba_data, test_size=0.25, random_state=100)\n",
    "nba_train = nba_train.sort_values(by='Pos')\n",
    "nba_test = nba_test.sort_values(by='Pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b15869-85cb-471e-9e5c-942408393a2b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## One-vs-Rest Logistic Regression\n",
    "\n",
    "As we saw at the beginning of the Decision Trees lecture, there is a natural extension of binary logistic regression from binary classification to multiclass classification called one-vs-rest logistic regression. In essence, one-vs-rest logistic regression simply builds one binary logistic regression classifier for each of the $N$ classes (in this scenario $N = 3$). We then predict the class corresponding to the classifier that gives the highest probability among the $N$ classes.\n",
    "\n",
    "\n",
    "### Question 5a\n",
    "\n",
    "In the cell below, set `logistic_regression_model` to be a one-vs-rest logistic regression model. Then, fit that model using the `AST` and `TRB` columns (in that order) from `nba_train` as our features, and `Pos3` as our response variable.\n",
    "\n",
    "Remember, `sklearn.linear_model.LogisticRegression` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)) has already been imported for you. There is an optional parameter **`multi_class`** you need to specify in order to make your model a multi-class one-vs-rest classifier. See the documentation for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7280b0-0370-485d-8f32-8460ec05faa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logistic_regression_model = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88206289",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2254d86e-2374-45bd-96b5-030ed3bdf957",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "### [Tutorial] Visualizing Performance\n",
    "\n",
    "To see our classifier in action, we can use `logistic_regression_model.predict` and see what it outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1c78d-f2f0-433e-8bed-210342b6e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "nba_train['Predicted (OVRLR) Pos3'] = logistic_regression_model.predict(nba_train[['AST', 'TRB']])\n",
    "nba_train[['AST', 'TRB', 'Pos3', 'Predicted (OVRLR) Pos3']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d566fc1-981e-4452-aaf8-d020709d3b6a",
   "metadata": {},
   "source": [
    "Our model does decently well here, as you can see visually above. Below, we compute the training accuracy; remember that `model.score()` computes accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb65611-18bb-43a6-84c5-cd637728bead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_training_accuracy = logistic_regression_model.score(nba_train[['AST', 'TRB']], nba_train['Pos3'])\n",
    "lr_training_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b79c84-4fc2-419e-b401-f8079950e49a",
   "metadata": {},
   "source": [
    "We can compute the test accuracy as well by looking at `nba_test` instead of `nba_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1cecad-8cf6-4f39-9d4c-73f1d64d05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_test_accuracy = logistic_regression_model.score(nba_test[['AST', 'TRB']], nba_test['Pos3'])\n",
    "lr_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275e0d40-ad26-4e34-ab33-419de198f419",
   "metadata": {},
   "source": [
    "Now, let's draw the decision boundary for this logistic regression classifier, and see how the classifier performs on both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb6197-0e73-4d8d-8354-624984070e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell to save the helper function.\n",
    "def plot_decision_boundaries(model, nba_dataset, title=None, ax=None):\n",
    "    sns_cmap = ListedColormap(np.array(sns.color_palette())[0:3, :])\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(0, 12, 0.02), np.arange(0, 16, 0.02))\n",
    "    Z_string = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    categories, Z_int = np.unique(Z_string, return_inverse = True)\n",
    "    Z_int = Z_int.reshape(xx.shape)\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    ax.contourf(xx, yy, Z_int, cmap = sns_cmap)\n",
    "    \n",
    "    sns.scatterplot(data = nba_dataset, x = 'AST', y = 'TRB', hue = 'Pos3', ax=ax)\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c12de-5d1f-4f89-be12-c8a9c4775ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to suppress all UserWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1cc317-a251-4793-b760-f94809be56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "plot_decision_boundaries(logistic_regression_model, nba_train, \"Logistic Regression on nba_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e47a944-f140-4cbe-a231-adb26cc28695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "plot_decision_boundaries(logistic_regression_model, nba_test, \"Logistic Regression on nba_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffe7bb8-f4d0-413e-b37d-5c820e6f6cd5",
   "metadata": {},
   "source": [
    "Our one-vs-rest logistic regression was able to find a linear decision boundary between the three classes. It generally classifies centers as players with a lot of rebounds, forwards as players with a medium number of rebounds and a low number of assists, and guards as players with a low number of rebounds. \n",
    "\n",
    "Note: In practice we would use many more features – we only used 2 here just so that we could visualize the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c6522-5801-4385-acd0-0e06619ed09e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "### Question 5b\n",
    "\n",
    "Let's now create a decision tree classifier on the same training data `nba_train`, and look at the resulting decision boundary. \n",
    "\n",
    "In the following cell, first, use `tree.DecisionTreeClassifier` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)) to fit a model using the same features and response as above, and call this model `decision_tree_model`. Set the `random_state` and `criterion` parameters to 42 and `entropy`, respectively.\n",
    "\n",
    "**Hint:** Your code will be mostly the same as the previous part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a220827-31bb-4652-9fad-4df257ffa36c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "decision_tree_model = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ade166",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a3f8b9-4163-43f3-a0c3-6fba37fa5a65",
   "metadata": {},
   "source": [
    "### [Tutorial] Decision Tree Performance\n",
    "\n",
    "Now, let's draw the decision boundary for this decision tree classifier, and see how the classifier performs on both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a353322-4008-4c70-be27-e33e14928060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "plot_decision_boundaries(decision_tree_model, nba_train, \"Decision Tree on nba_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f849d192-2139-4651-8afd-02866a394c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell. You may get a UserWarning--it is OK to ignore this warning.\n",
    "plot_decision_boundaries(decision_tree_model, nba_test, \"Decision Tree on nba_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5992f7bc-e862-47b4-a19b-40fd67c4c8ad",
   "metadata": {},
   "source": [
    "We compute the training and test accuracies of the decision tree model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43035c38-305b-455f-a47e-2da301aca6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_training_accuracy = decision_tree_model.score(nba_train[['AST', 'TRB']], nba_train['Pos3'])\n",
    "dt_test_accuracy = decision_tree_model.score(nba_test[['AST', 'TRB']], nba_test['Pos3'])\n",
    "dt_training_accuracy, dt_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7010ab7a-dfc2-48fd-bcf2-831ea0990a12",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Random Forests\n",
    "\n",
    "### Question 5c\n",
    "\n",
    "Let's now create a random forest classifier on the same training data `nba_train` and look at the resulting decision boundary. \n",
    "\n",
    "In the following cell, use `ensemble.RandomForestClassifier` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)) to fit a model using the same features and response as above, and call this model `random_forest_model`. Use 20 trees in your random forest classifier; set the `random_state` and `criterion` parameters to 42 and `entropy`, respectively.\n",
    "\n",
    "**Hint:** Your code for both parts will be mostly the same as the first few parts of this question.\n",
    "\n",
    "**Hint:** Look at the `n_estimators` parameter of `ensemble.RandomForestClassifier`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d5ff4-02af-442d-800c-ae45b398e464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_forest_model = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ccf410",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85cf394-ef84-4332-b736-e7bc187c457e",
   "metadata": {},
   "source": [
    "### [Tutorial] Random Forest Performance\n",
    "\n",
    "Now, let's draw the decision boundary for this random forest classifier, and see how the classifier performs on both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252317b-bb9f-42f7-accc-b873e5775f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell. You may get a UserWarning--it is OK to ignore this warning.\n",
    "plot_decision_boundaries(random_forest_model, nba_train, \"Random Forest on nba_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ed220-4143-46fa-b82a-9975e5c2033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell. You may get a UserWarning--it is OK to ignore this warning.\n",
    "plot_decision_boundaries(random_forest_model, nba_test, \"Random Forest on nba_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5784e5c0-11a0-41fd-a1f8-405335aca58b",
   "metadata": {},
   "source": [
    "We compute the training and test accuracies of the random forest model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721d2bd-c8cd-4ae7-853b-3c0b1d40ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "rf_train_accuracy = random_forest_model.score(nba_train[['AST', 'TRB']], nba_train['Pos3'])\n",
    "rf_test_accuracy = random_forest_model.score(nba_test[['AST', 'TRB']], nba_test['Pos3'])\n",
    "rf_train_accuracy, rf_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8726e-eefb-4fab-953a-6e75cf5d296b",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Compare/Contrast\n",
    "\n",
    "How do the three models you created (multiclass one-vs-rest logistic regression, decision tree, random forest) compare to each other?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e45f4b-803d-4a4b-98c9-054f7debf3ec",
   "metadata": {},
   "source": [
    "**Decision boundaries**: Run the below cell for your convenience. It overlays the decision boundaries for the train and test sets for each of the models you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c7e2f-8410-4cfd-9876-aac54b7cbfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "for j, (model, title) in enumerate([(logistic_regression_model, \"Logistic Regression\"),\n",
    "                                    (decision_tree_model, \"Decision Tree\"),\n",
    "                                    (random_forest_model, \"Random Forest\")]):\n",
    "    axs[0, j].set_title(title)\n",
    "    for i, nba_dataset in enumerate([nba_train, nba_test]):\n",
    "        plot_decision_boundaries(model, nba_dataset, ax=axs[i, j])\n",
    "        \n",
    "# reset leftmost ylabels\n",
    "axs[0, 0].set_ylabel(\"nba_train\\nTRB\")\n",
    "axs[1, 0].set_ylabel(\"nba_test\\nTRB\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c60f32-0516-4e28-933d-70ecd816e9c3",
   "metadata": {},
   "source": [
    "**Performance Metrics**: Run the below cell for your convenience. It summarizes the train and test accuracies for the three models you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a44f7-5f97-4eed-aafc-47297e185250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "train_accuracy = [lr_training_accuracy, lr_test_accuracy, dt_training_accuracy, dt_test_accuracy, rf_train_accuracy, rf_test_accuracy]\n",
    "index = ['OVR Logistic Regression', 'Decision Tree', 'Random Forest']\n",
    "df = pd.DataFrame([(lr_training_accuracy, lr_test_accuracy), \n",
    "                   (dt_training_accuracy, dt_test_accuracy),\n",
    "                   (rf_train_accuracy, rf_test_accuracy)], \n",
    "                  columns=['Training Accuracy', 'Test Accuracy'], index=index)\n",
    "df.plot.bar();\n",
    "plt.legend().remove() # remove legend from plot itself\n",
    "plt.gcf().legend(loc='lower right') # and add legend to bottom of figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77fd60-4b3a-416d-b031-b18f0d42f03f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 5d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57be2f1e-c93e-429d-967e-4990da33cdbc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "\n",
    "Looking at the three models, which model performed the best on the training set, and which model performed the best on the test set? How are the training and test accuracy related for the three models, and how do the decision boundaries generated for each of the three models relate to the model's performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca86e310",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc02a764-c3cb-4c90-86b4-d72b8b1e2bf2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Congratulations on finishing Homework 10!\n",
    "\n",
    "<img src=\"images/mitski.jpg\" width=\"500\"/>\n",
    "\n",
    "Mitski the cat congratulates you!\n",
    "\n",
    "### Course Content Feedback\n",
    "\n",
    "If you have any feedback about this assignment or about any of our other weekly assignments, lectures, or discussions, please fill out the [Course Content Feedback Form](https://forms.gle/owfPCGgnrju1xQEA9). Your input is valuable in helping us improve the quality and relevance of our content to better meet your needs and expectations!\n",
    "\n",
    "### Submission Instructions\n",
    "\n",
    "Below, you will see a cell. Running this cell will automatically generate a zip file with your autograded answers. Submit this file to the Homework 10 assignment on Gradescope. If you run into any issues when running this cell, [this section of the debugging guide](https://ds100.org/debugging-guide/autograder_gradescope/autograder_gradescope.html#why-does-grader.exportrun_teststrue-fail-if-all-previous-tests-passed) may help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547de54",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436a351",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b911c",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "otter": {
   "OK_FORMAT": true,
   "require_no_pdf_confirmation": true,
   "tests": {
    "q1b": {
     "name": "q1b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.all(df_numerical.applymap(lambda x: x in [0, 1]))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> df_standardized.shape == (51, 13)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1d": {
     "name": "q1d",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(s) == 13\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1e": {
     "name": "q1e",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> first_2_pcs.shape == (51, 2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(first_2_pcs.columns == ['pc1', 'pc2'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> (first_2_pcs.index == np.arange(51)).all()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 1 < entropy(nba_data['Pos3']) < 2\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 < gini_impurity(nba_data['Pos3']) < 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4c": {
     "name": "q4c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 1 < we_pos3_age_30 < 2\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5a": {
     "name": "q5a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> logistic_regression_model.multi_class == 'ovr'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5b": {
     "name": "q5b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> decision_tree_model.criterion == 'entropy'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> decision_tree_model.random_state == 42\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5c": {
     "name": "q5c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> random_forest_model.criterion == 'entropy'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> random_forest_model.random_state == 42\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
