{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 24: Demo 2 â€“ Data 100, Summer 2024\n",
    "\n",
    "Data 100, Summer 2024\n",
    "\n",
    "[Acknowledgments Page](https://ds100.org/su24/acks/) and UC Santa Cruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ds100_utils import *\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion-MNIST\n",
    "\n",
    "We will be using the Fashion-MNIST dataset, which is a cool little dataset with gray scale 28x28 images of articles of clothing.\n",
    "\n",
    "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747\n",
    "https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "print(\"Training images\", train_images.shape)\n",
    "print(\"Test images\", test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class names for this data are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "class_dict = {i:class_name for i,class_name in enumerate(class_names)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have loaded a lot of data which you can play with later (try building a classifier). \n",
    "\n",
    "For the purposes of this demo, let's take a small sample of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "n = 5000\n",
    "sample_idx = rng.choice(np.arange(len(train_images)), size=n, replace=False)\n",
    "\n",
    "# Invert and normalize the images so they look better\n",
    "img_mat = -1*train_images[sample_idx]\n",
    "img_mat = (img_mat - img_mat.min())/(img_mat.max() - img_mat.min())\n",
    "\n",
    "images = pd.DataFrame({\"images\": img_mat.tolist(), \n",
    "                   \"labels\": train_labels[sample_idx], \n",
    "                   \"class\": [class_dict[x] for x in train_labels[sample_idx]]})\n",
    "images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet of code visualizes the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, ncols=5, max_images=30):\n",
    "    # conver the subset of images into a n,28,28 matrix for facet visualization\n",
    "    img_mat = np.array(images.head(max_images)['images'].to_list())\n",
    "    fig = px.imshow(img_mat, color_continuous_scale='gray', \n",
    "                    facet_col = 0, facet_col_wrap=ncols,\n",
    "                    height = 220*int(np.ceil(len(images)/ncols)))\n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "    # Extract the facet number and convert it back to the class label.\n",
    "    fig.for_each_annotation(lambda a: a.update(text=images.iloc[int(a.text.split(\"=\")[-1])]['class']))\n",
    "    return fig\n",
    "\n",
    "show_images(images.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(images.groupby('class',as_index=False).sample(2), ncols=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "How would we visualize the entire dataset?  Let's use PCA to find a low dimensional representation of the images. \n",
    "\n",
    "First, let's understand the high-dimensional representation. We will extract the matrix of images from the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(images['images'].to_list())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now \"unroll\" the pixels into a single row vector 28*28 = 784 dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Center the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X - X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PCA (this time we use SKLearn):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "n_comps = 50 \n",
    "pca = PCA(n_components=n_comps)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining PCA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a line plot and show markers\n",
    "px.line(y=pca.explained_variance_ratio_ *100, markers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of data is explained in first two or three dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[['z1', 'z2', 'z3']] = pca.transform(X)[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(images, x='z1', y='z2', hover_data=['labels'], \n",
    "           width = 800, height = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(images, x='z1', y='z2', color='class', hover_data=['labels'], \n",
    "           width = 800, height = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(images, x='z1', y='z2', z='z3', color='class', hover_data=['labels'], \n",
    "              width=1000, height=800)\n",
    "# set marker size to 5\n",
    "fig.update_traces(marker=dict(size=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison to just some random projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_basis = np.random.randn(784, 3)\n",
    "images[['z1_rand', 'z2_rand', 'z3_rand']] = X @ rand_basis\n",
    "px.scatter_3d(images, x='z1_rand', y='z2_rand', z='z3_rand', color='class', hover_data=['labels'],  \n",
    "              width=1000, height=800).update_traces(marker=dict(size=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying other methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the below cell might take some time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne_model = TSNE(n_components=3, random_state=0, perplexity=30, learning_rate=200, n_iter=1000)\n",
    "tsne_comps = tsne_model.fit_transform(X)\n",
    "images[['tsne1', 'tsne2', 'tsne3']] = tsne_comps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(images, x='tsne1', y='tsne2', color='class', hover_data=['labels'],\n",
    "              width=1000, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(images, x='tsne1', y='tsne2', z='tsne3', color='class', hover_data=['labels'],\n",
    "              width=1000, height=800).update_traces(marker=dict(size=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding a lower dimensional basis for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the t-SNE vectors. Note that all embeddings are built off of the principal components, which are rotations of the original features.\n",
    "\n",
    "When we add class labels to the visualization, notice that t-SNE's clusters correspond reasonably well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply PCA to a subset of the data\n",
    "\n",
    "Let's see if we can build a better embedding for the subset of the data that corresponds to tough images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Coat', 'Pullover']\n",
    "tough_images = images[images['class'].isin(classes)].copy()\n",
    "show_images(tough_images.sample(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(tough_images['images'].to_list())\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "X = X - X.mean(axis=0)\n",
    "zs = PCA(n_components=3).fit_transform(X)\n",
    "tough_images[['z1', 'z2', 'z3']] = zs\n",
    "px.scatter_3d(tough_images, x='z1', y='z2', z='z3', color='class', hover_data=['labels'],\n",
    "              width=1000, height=800).update_traces(marker=dict(size=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression on these hard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "model = lm.LogisticRegression(max_iter=1000)\n",
    "y = tough_images['class'] == \"Coat\"\n",
    "model.fit(zs, y)\n",
    "np.mean(model.predict(zs) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "model = lm.LogisticRegression(max_iter=1000)\n",
    "y = tough_images['class'] == \"Coat\"\n",
    "model.fit(X, y)\n",
    "np.mean(model.predict(X) == y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
